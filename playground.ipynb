{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teacher_query_tools import ANLITeacherQuerier, CQATeacherQuerier, ESNLITeacherQuerier, SVAMPTeacherQuerier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacher Querier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "anliTQ = ANLITeacherQuerier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yml = anliTQ.read_yaml_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'anli1',\n",
       " 'templates': {1: {'id': 1,\n",
       "   'system_message': '',\n",
       "   'user_message': '{premise} Based on that information, is the claim: {hypothesis} true, false, or inconclusive? Answer with a one sentence explanation.',\n",
       "   'label_parse': \"r'(True|False|Inconclusive)'\",\n",
       "   'explanation': True},\n",
       "  2: {'id': 2,\n",
       "   'system_message': 'You are given a context in the form of a short premise and a hypothesis about the premise. Your task is to label if the hypothesis is a \"contradiction\" (if the hypothesis contradicts the premise), an \"entailment\" (if the hypothesis entails the premise), or \"neutral\" (if the hypothesis does not contradict or entail the premise) to the premise. Also, explain very briefly (one sentence, maximum twenty words) why it is that label, but do not repeat the whole hypothesis in your explanation.',\n",
       "   'user_message': 'premise: {premise}\\\\nhypothesis: {hypothesis}',\n",
       "   'label_parse': \"r'(entailment|contradiction|neutral)'\",\n",
       "   'explanation': True},\n",
       "  3: {'id': 3,\n",
       "   'system_message': '',\n",
       "   'user_message': '{premise} Based on that information, is the claim: {hypothesis} true, false, or inconclusive? Answer without an explanation.',\n",
       "   'label_parse': \"r'(True|False|Inconclusive)'\",\n",
       "   'explanation': False}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alexandra Lendon Bastedo (9 March 1946 â€“ 12 January 2014) was a British actress, best known for her role as secret agent Sharron Macready in the 1968 British espionage/science fiction adventure series \"The Champions\". She has been cited as a sex symbol of the 1960s and 1970s. Bastedo was a vegetarian and animal welfare advocate. Based on that information, is the claim: Bastedo didn't keep any pets because of her views on animal rights. true, false, or inconclusive? Answer with a one sentence explanation.\n",
      "RESPONSE:\n",
      "Inconclusive, as there is no information provided to confirm or deny whether Bastedo kept any pets despite her views on animal rights.\n"
     ]
    }
   ],
   "source": [
    "anliTQ._query(split=\"train\", idx=2, prompt_template_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERYING EXAMPLE 15/15...\n",
      "Batch Query completed! (Skipped 0 queries as they were already queried and stored.)\n",
      "Total Prompt Tokens: 1884\n",
      "Total Completion Tokens: 421\n",
      "Total Costs: $0.0036679999999999994\n"
     ]
    }
   ],
   "source": [
    "anliTQ._batch_query(split=\"train\", n=15, prompt_template_id=1, force_query=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "svampTQ = SVAMPTeacherQuerier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERYING EXAMPLE 12/12...\n",
      "Batch Query completed! (Skipped 0 queries as they were already queried and stored.)\n",
      "Total Prompt Tokens: 658\n",
      "Total Completion Tokens: 735\n",
      "Total Costs: $0.002457\n"
     ]
    }
   ],
   "source": [
    "svampTQ._batch_query(split=\"test\", n=12, prompt_template_id=1, force_query=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "esnli = ESNLITeacherQuerier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERYING EXAMPLE 13/13...\n",
      "Batch Query completed! (Skipped 12 queries as they were already queried and stored.)\n",
      "Total Prompt Tokens: 54\n",
      "Total Completion Tokens: 34\n",
      "Total Costs: $0.00014900000000000002\n"
     ]
    }
   ],
   "source": [
    "esnli._batch_query(split=\"train\", n=13, prompt_template_id=1, force_query=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqaTQ = CQATeacherQuerier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERYING EXAMPLE 10/10...\n",
      "Batch Query completed! (Skipped 0 queries as they were already queried and stored.)\n",
      "Total Prompt Tokens: 576\n",
      "Total Completion Tokens: 99\n",
      "Total Costs: $0.001062\n"
     ]
    }
   ],
   "source": [
    "cqaTQ._batch_query(split=\"train\", n=10, prompt_template_id=1, force_query=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\master-thesis\\ZeroShot-step-by-step-distillation\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from teacher_response_parser import TeacherResponseParser\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = TeacherResponseParser(\"cqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neutral', None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(\"(entailment|contradiction|neutral)\", re.IGNORECASE|re.DOTALL)\n",
    "parser.parse_response(\"The label is: neutral. The explanation is: This is a test explanation.\", pattern=pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ('d) math problem', None),\n",
       " 1: ('bridge', None),\n",
       " 2: ('upright', None),\n",
       " 3: ('c) minnesota', None),\n",
       " 4: ('destroyer', None),\n",
       " 5: ('d) canada', None),\n",
       " 6: ('a) city', None),\n",
       " 7: ('a) in charge of project', None),\n",
       " 8: ('a) punishment', None),\n",
       " 9: ('c) marriage', None)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse_response_batch(split=\"train\", prompt_template_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "s = \"Tell me a {adjective} joke about {content}.\"\n",
    "\n",
    "s.format(**{\"adjective\": \"funny\", \"content\": \"chickens\", \"mashall\": \"mashall\"})\n",
    "#(**{\"adjective\": \"funny\", \"content\": \"chickens\", \"mashall\": \"mashall\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
