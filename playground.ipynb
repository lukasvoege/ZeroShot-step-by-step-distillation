{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.teacher_query_tools import ANLITeacherQuerier, CQATeacherQuerier, ESNLITeacherQuerier, SVAMPTeacherQuerier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacher Querier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "anliTQ = ANLITeacherQuerier(chat_model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Alexandra Lendon Bastedo (9 March 1946 â€“ 12 January 2014) was a British actress, best known for her role as secret agent Sharron Macready in the 1968 British espionage/science fiction adventure series \"The Champions\". She has been cited as a sex symbol of the 1960s and 1970s. Bastedo was a vegetarian and animal welfare advocate. Based on that information, is the claim: Bastedo didn't keep any pets because of her views on animal rights. true, false, or inconclusive? Answer without an explanation.\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "The model `gpt-4` does not exist or you do not have access to it. Learn more: https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Projects\\MasterThesis\\ZeroShot-step-by-step-distillation\\playground.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Projects/MasterThesis/ZeroShot-step-by-step-distillation/playground.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m anliTQ\u001b[39m.\u001b[39;49m_query(split\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m, idx\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, prompt_template_id\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, dont_save\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\ZeroShot-step-by-step-distillation\\src\\teacher_query_tools.py:253\u001b[0m, in \u001b[0;36mANLITeacherQuerier._query\u001b[1;34m(self, split, idx, prompt_template_id, dont_save)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_query\u001b[39m(\u001b[39mself\u001b[39m, split: \u001b[39mstr\u001b[39m, idx: \u001b[39mint\u001b[39m, prompt_template_id: \u001b[39mint\u001b[39m, dont_save: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    252\u001b[0m     template_tuple \u001b[39m=\u001b[39m [(\u001b[39m\"\u001b[39m\u001b[39mpremise\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpremise\u001b[39m\u001b[39m\"\u001b[39m), (\u001b[39m\"\u001b[39m\u001b[39mhypothesis\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhypothesis\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[1;32m--> 253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquery(split, idx, prompt_template_id, template_tuple, dont_save)\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\ZeroShot-step-by-step-distillation\\src\\teacher_query_tools.py:204\u001b[0m, in \u001b[0;36mTeacherQuerier.query\u001b[1;34m(self, split, idx, prompt_template_id, template_tuple, dont_save)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchat_model, OpenAI):\n\u001b[0;32m    202\u001b[0m     \u001b[39mprint\u001b[39m(chain\u001b[39m.\u001b[39mprompt\u001b[39m.\u001b[39mformat(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{tup[\u001b[39m0\u001b[39m]: example[tup[\u001b[39m1\u001b[39m]] \u001b[39mfor\u001b[39;00m tup \u001b[39min\u001b[39;00m template_tuple}))\n\u001b[1;32m--> 204\u001b[0m response \u001b[39m=\u001b[39m chain\u001b[39m.\u001b[39;49mrun({tup[\u001b[39m0\u001b[39;49m]: example[tup[\u001b[39m1\u001b[39;49m]] \u001b[39mfor\u001b[39;49;00m tup \u001b[39min\u001b[39;49;00m template_tuple})\n\u001b[0;32m    205\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRESPONSE:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mresponse\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    207\u001b[0m \u001b[39m# save results\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\langchain\\chains\\base.py:436\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    435\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 436\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[0;32m    437\u001b[0m         _output_key\n\u001b[0;32m    438\u001b[0m     ]\n\u001b[0;32m    440\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    441\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[0;32m    442\u001b[0m         _output_key\n\u001b[0;32m    443\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\langchain\\chains\\base.py:243\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    242\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 243\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    244\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    245\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[0;32m    246\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    247\u001b[0m )\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\langchain\\chains\\base.py:237\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[0;32m    231\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    232\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m    233\u001b[0m     inputs,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    236\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 237\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    238\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    239\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    240\u001b[0m     )\n\u001b[0;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    242\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\langchain\\chains\\llm.py:92\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[0;32m     88\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     89\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m     90\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     91\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m---> 92\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m     93\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\langchain\\chains\\llm.py:102\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m    101\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[0;32m    103\u001b[0m     prompts,\n\u001b[0;32m    104\u001b[0m     stop,\n\u001b[0;32m    105\u001b[0m     callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    106\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_kwargs,\n\u001b[0;32m    107\u001b[0m )\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\langchain\\llms\\base.py:188\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[0;32m    181\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    182\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    186\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    187\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[1;32m--> 188\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\langchain\\llms\\base.py:281\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    276\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    277\u001b[0m         )\n\u001b[0;32m    278\u001b[0m     run_managers \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[0;32m    279\u001b[0m         dumpd(\u001b[39mself\u001b[39m), prompts, invocation_params\u001b[39m=\u001b[39mparams, options\u001b[39m=\u001b[39moptions\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 281\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[0;32m    282\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    283\u001b[0m     )\n\u001b[0;32m    284\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[0;32m    285\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\langchain\\llms\\base.py:225\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n\u001b[0;32m    224\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 225\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    226\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m    227\u001b[0m \u001b[39mfor\u001b[39;00m manager, flattened_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\langchain\\llms\\base.py:212\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_helper\u001b[39m(\n\u001b[0;32m    203\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    204\u001b[0m     prompts: List[\u001b[39mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    209\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    210\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 212\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[0;32m    213\u001b[0m                 prompts,\n\u001b[0;32m    214\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[0;32m    215\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[0;32m    216\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    217\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    218\u001b[0m             )\n\u001b[0;32m    219\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    220\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[0;32m    221\u001b[0m         )\n\u001b[0;32m    222\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    223\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\langchain\\llms\\openai.py:319\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 319\u001b[0m     response \u001b[39m=\u001b[39m completion_with_retry(\u001b[39mself\u001b[39;49m, prompt\u001b[39m=\u001b[39;49m_prompts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[0;32m    320\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    321\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstreaming:\n\u001b[0;32m    322\u001b[0m     \u001b[39m# Can't update token usage if streaming\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\langchain\\llms\\openai.py:89\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[1;34m(llm, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m     87\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 89\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\tenacity\\__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[0;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[1;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\concurrent\\futures\\_base.py:437\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    436\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    439\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\concurrent\\futures\\_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    388\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 389\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    390\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    392\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\langchain\\llms\\openai.py:87\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m---> 87\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\openai\\api_resources\\completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    705\u001b[0m         ),\n\u001b[0;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\openai\\api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    765\u001b[0m     )\n\u001b[0;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: The model `gpt-4` does not exist or you do not have access to it. Learn more: https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4."
     ]
    }
   ],
   "source": [
    "anliTQ._query(split=\"train\", idx=2, prompt_template_id=3, dont_save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Query completed! (Skipped 41 queries as they were already queried and stored.)\n",
      "Total Prompt Tokens: 711\n",
      "Total Completion Tokens: 8\n",
      "Total Costs: $0.0010825000000000001\n"
     ]
    }
   ],
   "source": [
    "anliTQ._batch_query(split=\"train\", idxs=list(range(47)), prompt_template_id=3, force_query=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "svampTQ = SVAMPTeacherQuerier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Query completed! (Skipped 30 queries as they were already queried and stored.)\n",
      "Total Prompt Tokens: 566\n",
      "Total Completion Tokens: 635\n",
      "Total Costs: $0.002119\n"
     ]
    }
   ],
   "source": [
    "svampTQ._batch_query(split=\"train\", idxs=list(range(41)), prompt_template_id=1, force_query=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "esnli = ESNLITeacherQuerier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Query completed! (Skipped 2 queries as they were already queried and stored.)\n",
      "Total Prompt Tokens: 0\n",
      "Total Completion Tokens: 0\n",
      "Total Costs: $0\n"
     ]
    }
   ],
   "source": [
    "esnli._batch_query(split=\"train\", idxs=[0, 34191], prompt_template_id=1, force_query=False, dont_save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqaTQ = CQATeacherQuerier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Query completed! (Skipped 3 queries as they were already queried and stored.)\n",
      "Total Prompt Tokens: 148\n",
      "Total Completion Tokens: 58\n",
      "Total Costs: $0.000338\n"
     ]
    }
   ],
   "source": [
    "cqaTQ._batch_query(split=\"train\", idxs=[0, 1, 2, 100, 200], prompt_template_id=2, force_query=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.teacher_response_parser import SVAMPTeacherResponseParser, ESNLITeacherResponseParser, CQATeacherResponseParser, ANLITeacherResponseParser\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ANLITeacherResponseParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neutral', None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(\"(\\d+)\", re.IGNORECASE|re.DOTALL)\n",
    "parser.parse_response(\"In each row, there are 30 crayons, so in 7 rows there are 7 * 30 = <<7*30=210>>210 crayons. Answer: \\\\boxed{210}.\", pattern=pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\"(.+\\\\b)(\\d+)\")\n",
    "match = pattern.search(\"In each row, there are 30 crayons, so in 7 rows there are 7 * 30 <<7*30=210>>210 crayons. Answer: \\\\boxed{210}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5333: ('contradiction',\n",
       "  'The Other One is actually a solo album by Bob Welch, not a TOOL album. Additionally, there is no information to suggest that Bob Welch provided backing vocals for TOOL.'),\n",
       " 8443: ('contradiction',\n",
       "  'The Living and the Dead was not renewed for 7 seasons. It was a miniseries, meaning it only had one season consisting of six episodes.'),\n",
       " 16741: ('contradiction',\n",
       "  'The statement correctly describes the films produced by the U.S. film studio 20th Century Fox Film Corporation, not the U.K. film studio.'),\n",
       " 735: ('contradiction',\n",
       "  'The South Kalgoorlie Gold Mine is not referred to as the North Kal Mines. It is a separate entity from the North Kal Mines.'),\n",
       " 7559: ('contradiction',\n",
       "  \"The Cats of Copenhagen was written by James Joyce, but it was not published by him during his lifetime. It was posthumously published in 2012, long after Joyce's death, when his work entered the public domain in certain jurisdictions.\"),\n",
       " 16652: ('neutral',\n",
       "  'The information does not specify the exact season in which Ward retired.'),\n",
       " 13064: ('neutral',\n",
       "  'whether Katie Liu Leung graduated with honors after studying art and design at the University of the Arts, London.'),\n",
       " 11538: ('entailment',\n",
       "  'Captain Henry T. Elrod, after whom the USS Elrod is named, was a Marine aviator who served as a pilot during World War II. He played a heroic role in the defense of Wake Island and was posthumously awarded the Medal of Honor.'),\n",
       " 13776: ('neutral',\n",
       "  'While it is known that Ted Tetzlaff directed the film World Premiere, it is unclear whether this was his directorial debut or if he had directed any films prior to it.'),\n",
       " 2325: ('entailment',\n",
       "  'The novel is primarily narrated through the perspectives of the two main characters, Arturo Belano and Ulises Lima, who are both poets. They recount their experiences and their search for the elusive poet CesÃ¡rea Tinajero. The narrative also includes sections from other characters and different time periods, but the central viewpoint is indeed that of the two poets.'),\n",
       " 8253: ('contradiction',\n",
       "  'Incline Village is a census-designated place (CDP) in Washoe County, Nevada on the north shore of Lake Tahoe. However, it was not designed as a community for Native Americans. The population was indeed 8,777 at the 2010 census.'),\n",
       " 10684: ('entailment',\n",
       "  'The film, \"The Strangers,\" does follow a young couple who are terrorized by three masked assailants over the course of an evening at a remote summer home.'),\n",
       " 16845: ('contradiction',\n",
       "  'She was born on March 24, 1897, and died on July 4, 1979, making her 82 years old at the time of her death.'),\n",
       " 9044: ('neutral',\n",
       "  'Although the marketing of Killian\\'s red beer claims a legacy to an Irish \"original recipe,\" it does not provide specific information about the actual consumption patterns of Irish people. Additionally, the fact that Killian\\'s red beer is brewed in France by Heineken France and in the USA by MillerCoors under license suggests that it is not exclusively consumed by Irish people. Further data would be required to make a conclusive determination.'),\n",
       " 8094: ('entailment', None),\n",
       " 6442: ('neutral',\n",
       "  'While it is mentioned that Tigris and Euphrates was published by Hans im GlÃ¼ck in 1997, there is no mention of any other games that were published by the company in that year.'),\n",
       " 9004: ('neutral',\n",
       "  'The given information does not mention the specific filming location of the series, so it is not possible to determine with certainty whether it was filmed in Vancouver or not.'),\n",
       " 3429: ('neutral',\n",
       "  'The information does not provide any explicit details or statements about his personal feelings or enjoyment of being a politician.'),\n",
       " 6333: ('contradiction',\n",
       "  'Mark Rylance did indeed appear in the film Institute Benjamenta.'),\n",
       " 12998: ('neutral',\n",
       "  'The description mentions that it is designed to house educational and meditational activities, but it does not explicitly state that it is specifically a place of worship. Without further information or clarification, it cannot be definitively determined if it is a worshipping house.'),\n",
       " 3589: ('entailment', None),\n",
       " 1210: ('contradiction',\n",
       "  'Tito Puente, the mambo musician and percussionist, passed away on May 31, 2000. Therefore, he is no longer alive to perform concerts at the Tito Puente Amphitheatre in San Juan, Puerto Rico.'),\n",
       " 16922: ('neutral',\n",
       "  \"The information provided states that Kyle Schickner, the founder, is a bisexual civil rights activist, suggesting a positive stance on LGBTQ+ issues. However, the information does not explicitly state the company's stance on gay marriage.\"),\n",
       " 6422: ('neutral',\n",
       "  'The information does not specify the exact place of his birth.'),\n",
       " 2021: ('neutral',\n",
       "  'The outcome of a tennis match does not necessarily determine the income earned by the players. Factors such as tournament prize money, sponsorship deals, appearance fees, and individual performance can all impact the income of players.'),\n",
       " 14365: ('neutral',\n",
       "  'While Rabbi Dovid Schlomo Novoseller is mentioned as a descendant of Rabbi Levi Yitzchok of Berditchev, it does not explicitly state that he is his grandson. Further information would be needed to determine the exact relationship between the two individuals.'),\n",
       " 7695: ('entailment', None),\n",
       " 3703: ('neutral',\n",
       "  'Although she trained and danced in Russia, it is not explicitly stated whether she learned to speak the Russian language during her time at the Bolshoi Ballet Academy or while working at the Kremlin Ballet Theater.'),\n",
       " 14783: ('entailment',\n",
       "  'George Washington Baines, Sr. did serve briefly as the President of Baylor University at its first location in Independence, Texas.'),\n",
       " 10591: ('contradiction',\n",
       "  'The claim contradicts itself by stating that the event occurred in both 2008 and 2005. Additionally, the information provided indicates that the Miss Peru 2008 pageant was held on May 1, 2008, and the winner represented Peru at the Miss Universe 2008 pageant, which aligns with the correct year.'),\n",
       " 16430: ('contradiction',\n",
       "  'The Parma trolleybus system has been in operation since 1953, which means it was not in use during the 1940s.'),\n",
       " 11505: ('neutral',\n",
       "  'While Gurstelle is a columnist and contributing editor at \"Popular Science\" magazine, it does not necessarily mean that he is known by all scientists. The claim does not provide sufficient evidence to determine the extent of his recognition among scientists.'),\n",
       " 10362: ('entailment',\n",
       "  'It is stated in the information provided that Roderick played professionally in the Major Indoor Soccer League, which confirms that he played soccer indoors.'),\n",
       " 6844: ('entailment',\n",
       "  'Dyllan McGee has produced several shows that have been aired on television networks such as HBO and PBS. Some examples include \"Gloria: In Her Own Words\" (HBO), \"Finding Your Roots with Henry Louis Gates, Jr.\" (PBS), and \"MAKERS: Women Who Make America.\" Furthermore, McGee is the Founder and Executive Producer of AOL\\'s MAKERS, which is also a TV show.'),\n",
       " 16644: ('contradiction',\n",
       "  'The song \"Zaalima\" from the film \"Raees\" is sung by Arijit Singh and Harshdeep Kaur, not JAM8. JAM8 is the composer of the song, not the singer.'),\n",
       " 1493: ('contradiction',\n",
       "  'The former Isanti County Courthouse, now known as Court House Square, is located at that address. Therefore, the current courthouse must be located elsewhere.'),\n",
       " 123: ('entailment', None),\n",
       " 11055: ('neutral',\n",
       "  \"While we know that Anley was commissioned to research women's prisons, we do not have enough information to determine her stance on the treatment of women in prisons. Further research would be needed to ascertain her views on this specific issue.\"),\n",
       " 5834: ('contradiction',\n",
       "  'The claim states that Clerodendrum was found in 1980, but the information given does not mention anything about the time of discovery. However, it does mention that Clerodendrum was transferred from Verbenaceae to Lamiaceae in the 1990s, which indicates that it was known before that time.'),\n",
       " 15287: ('entailment',\n",
       "  'According to the information provided, Abesim is a town located in the Sunyani Municipal District, which is within the Brong-Ahafo Region of Ghana.'),\n",
       " 12745: ('neutral',\n",
       "  \"The information provided only mentions the technical details and operations of the railway line, such as its length and the fact that it is part of the BNSF's Northern Transcon. It does not provide any information or data about the popularity or usage of the Aurora Subdivision. Therefore, without additional information, it is not possible to determine whether it is popular or unpopular.\"),\n",
       " 4074: ('entailment',\n",
       "  'According to the information provided, FuÃŸball Club SÃ¼dburgenland (HOCO SÃ¼dburgenland) has played in the Ã–FB-Frauenliga since the 2003-04 season.'),\n",
       " 3599: ('entailment',\n",
       "  \"Bailey's Irish Cream is one of the most well-known and popular brands of Irish cream worldwide. It has a strong presence in the largest markets for Irish cream, including the United Kingdom, Canada, and the United States. Bailey's has been successful in establishing itself as a leading brand in the cream liqueur category and is often the go-to choice for consumers when they think of Irish cream. However, it is important to note that this claim could be subjective and dependent on individual perspectives.\"),\n",
       " 2099: ('entailment', None),\n",
       " 7026: ('entailment',\n",
       "  'Tear Out The Heart signed with Victory Records in 2012 and released their first full-length record, \"Violence\", in 2013. They then released their second full-length album, \"Dead, Everywhere\", on January 27, 2015, which is two years after the release of their first album.'),\n",
       " 3617: ('entailment',\n",
       "  'Can\\'t Leave \\'em Alone\" is indeed an R&B song written by Ciara, LaShawn Daniels, Rodney Jerkins, and 50 Cent.'),\n",
       " 322: ('contradiction',\n",
       "  'If Fred Berger was born on May 10, 1981, then he would have been 35 years old when he won the Golden Globe for \"La La Land\" in 2016.'),\n",
       " 12654: ('entailment', None),\n",
       " 4417: ('neutral',\n",
       "  'While it is mentioned that Joseph Groome Towers are three thirteen-storey tower blocks, it does not specify whether they are connected or separate buildings. Therefore, without further information, we cannot determine if they are one building or three separate ones.'),\n",
       " 7048: ('entailment', None)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse_response_batch(split=\"train\", prompt_template_id=100, verbose= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('In each row, there are 30 crayons, so in 7 rows there are 7 * 30 <<7*30=210>>210 crayons. Answer: \\\\boxed{',\n",
       " '210')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ('42', None),\n",
       " 1: ('210', None),\n",
       " 2: ('34', 'Julia played with a total of'),\n",
       " 3: ('6', None),\n",
       " 4: ('7', None),\n",
       " 5: ('1088', 'The mailman should give a total of'),\n",
       " 6: ('0.5', 'Each person ate 0.5 crackers and'),\n",
       " 7: ('280', None),\n",
       " 8: ('5', None),\n",
       " 9: ('13', None),\n",
       " 10: ('12', None),\n",
       " 11: ('150', None),\n",
       " 12: ('60', None),\n",
       " 13: ('69', None),\n",
       " 14: ('9', None),\n",
       " 15: ('204', 'The farmer picked a total of'),\n",
       " 16: ('180', 'The machine made a total of'),\n",
       " 17: ('18', None),\n",
       " 18: ('18', 'The number of birds sitting on the fence is'),\n",
       " 19: ('8', None),\n",
       " 20: ('2', None),\n",
       " 21: ('60', 'The depth of the water was'),\n",
       " 22: ('66', 'The grasshopper and the frog jumped a total of'),\n",
       " 23: ('89', None),\n",
       " 24: ('130', None),\n",
       " 25: ('2', None),\n",
       " 26: ('32', None),\n",
       " 27: ('154', None),\n",
       " 28: ('345', None),\n",
       " 29: ('1', None),\n",
       " 696: ('2', None),\n",
       " 667: ('4', None),\n",
       " 63: ('12', None),\n",
       " 533: ('26', None),\n",
       " 66: ('3', None),\n",
       " 621: ('51', None),\n",
       " 346: ('7', None),\n",
       " 490: ('238', None),\n",
       " 760: ('4', None),\n",
       " 456: ('1', None)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse_response_batch(split=\"train\", prompt_template_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "s = \"Tell me a {adjective} joke about {content}.\"\n",
    "\n",
    "s.format(**{\"adjective\": \"funny\", \"content\": \"chickens\", \"mashall\": \"mashall\"})\n",
    "#(**{\"adjective\": \"funny\", \"content\": \"chickens\", \"mashall\": \"mashall\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = utils.Metadata()\n",
    "c2 = utils.OtherMeta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'another static'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2.static_thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.teacher_response_evaluator import TeacherResponseEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = TeacherResponseEvaluator(\"esnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.76,\n",
       " 'n_correct': 38,\n",
       " 'n_wrong': 12,\n",
       " 'n_parse_errors': 0,\n",
       " 'n_none_responses': 0,\n",
       " 'total_responses': 50,\n",
       " 'total_length_of_explanations': 7145}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate_responses_split(split = \"train\", prompt_template_id = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not parse '8 customers left than those that stayed behind.' with pattern 're.compile('(.+[\\\\s{\\\\$Ã¢â€šÂ¬])(\\\\d*\\\\.?\\\\d+)', re.IGNORECASE|re.DOTALL)'\n",
      "Could not parse '137 more students suggested mashed potatoes than those that suggested bacon.' with pattern 're.compile('(.+[\\\\s\\\\{\\\\$Ã¢â€šÂ¬])(\\\\d*\\\\.?\\\\d+)', re.IGNORECASE|re.DOTALL)'\n",
      "Could not parse '34 bird families were living near the mountain at the start.' with pattern 're.compile('(.+[\\\\s\\\\{\\\\$Ã¢â€šÂ¬])(\\\\d*\\\\.?\\\\d+)', re.IGNORECASE|re.DOTALL)'\n",
      "Could not parse '65 more students suggested mashed potatoes than those that suggested tomatoes.' with pattern 're.compile('(.+[\\\\s\\\\{\\\\$Ã¢â€šÂ¬])(\\\\d*\\\\.?\\\\d+)', re.IGNORECASE|re.DOTALL)'\n",
      "Could not parse '30 campers went rowing and hiking in all.' with pattern 're.compile('(.+[\\\\s\\\\{\\\\$Ã¢â€šÂ¬])(\\\\d*\\\\.?\\\\d+)', re.IGNORECASE|re.DOTALL)'\n",
      "Best prompt template for svamp is 2, with accuracy: 0.7936507936507936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teacher_writer import TeacherWriter\n",
    "tw = TeacherWriter(\"svamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix = {\"label\": {1: range(10)}, \"explanation\": {2: range(10)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw.write_teacher_responses(split=\"train\", prompt_template_id_mix=mix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plain Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! As an AI, I don't have emotions, but I'm here to help you. How can I assist you today?\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model = ChatOpenAI(model = \"gpt-3.5-turbo\", temperature=1.1, max_tokens=200, request_timeout=10)\n",
    "\n",
    "chat_model.predict(\"Hi, how are you today?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
