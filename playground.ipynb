{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teacher_query_tools import ANLITeacherQuerier, CQATeacherQuerier, ESNLITeacherQuerier, SVAMPTeacherQuerier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacher Querier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "anliTQ = ANLITeacherQuerier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alexandra Lendon Bastedo (9 March 1946 â€“ 12 January 2014) was a British actress, best known for her role as secret agent Sharron Macready in the 1968 British espionage/science fiction adventure series \"The Champions\". She has been cited as a sex symbol of the 1960s and 1970s. Bastedo was a vegetarian and animal welfare advocate. Based on that information, is the claim: Bastedo didn't keep any pets because of her views on animal rights. true, false, or inconclusive? Answer with a one sentence explanation.\n",
      "RESPONSE:\n",
      "Inconclusive, as there is no information provided to confirm or deny whether Bastedo kept any pets despite her views on animal rights.\n"
     ]
    }
   ],
   "source": [
    "anliTQ._query(split=\"train\", idx=2, prompt_template_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERYING EXAMPLE 40/40...\n",
      "Batch Query completed! (Skipped 15 queries as they were already queried and stored.)\n",
      "Total Prompt Tokens: 3047\n",
      "Total Completion Tokens: 42\n",
      "Total Costs: $0.0046545\n"
     ]
    }
   ],
   "source": [
    "anliTQ._batch_query(split=\"train\", n=40, prompt_template_id=3, force_query=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "svampTQ = SVAMPTeacherQuerier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERYING EXAMPLE 30/30...\n",
      "Batch Query completed! (Skipped 10 queries as they were already queried and stored.)\n",
      "Total Prompt Tokens: 973\n",
      "Total Completion Tokens: 1313\n",
      "Total Costs: $0.0040855\n"
     ]
    }
   ],
   "source": [
    "svampTQ._batch_query(split=\"train\", n=30, prompt_template_id=1, force_query=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "esnli = ESNLITeacherQuerier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERYING EXAMPLE 10/10...\n",
      "Batch Query completed! (Skipped 0 queries as they were already queried and stored.)\n",
      "Total Prompt Tokens: 560\n",
      "Total Completion Tokens: 28\n",
      "Total Costs: $0.0008960000000000001\n"
     ]
    }
   ],
   "source": [
    "esnli._batch_query(split=\"train\", n=10, prompt_template_id=3, force_query=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqaTQ = CQATeacherQuerier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERYING EXAMPLE 25/25...\n",
      "Batch Query completed! (Skipped 20 queries as they were already queried and stored.)\n",
      "Total Prompt Tokens: 326\n",
      "Total Completion Tokens: 144\n",
      "Total Costs: $0.000777\n"
     ]
    }
   ],
   "source": [
    "cqaTQ._batch_query(split=\"train\", n=25, prompt_template_id=2, force_query=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teacher_response_parser import SVAMPTeacherResponseParser, ESNLITeacherResponseParser, CQATeacherResponseParser, ANLITeacherResponseParser\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ANLITeacherResponseParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neutral', None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(\"(\\d+)\", re.IGNORECASE|re.DOTALL)\n",
    "parser.parse_response(\"In each row, there are 30 crayons, so in 7 rows there are 7 * 30 = <<7*30=210>>210 crayons. Answer: \\\\boxed{210}.\", pattern=pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\"(.+\\\\b)(\\d+)\")\n",
    "match = pattern.search(\"In each row, there are 30 crayons, so in 7 rows there are 7 * 30 <<7*30=210>>210 crayons. Answer: \\\\boxed{210}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('In each row, there are 30 crayons, so in 7 rows there are 7 * 30 <<7*30=210>>210 crayons. Answer: \\\\boxed{',\n",
       " '210')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ('contradiction', None),\n",
       " 1: ('contradiction', None),\n",
       " 2: ('neutral', None),\n",
       " 3: ('neutral', None),\n",
       " 4: ('neutral', None),\n",
       " 5: ('entailment', None),\n",
       " 6: ('contradiction', None),\n",
       " 7: ('entailment', None),\n",
       " 8: ('entailment', None),\n",
       " 9: ('neutral', None),\n",
       " 10: ('neutral', None),\n",
       " 11: ('entailment', None),\n",
       " 12: ('neutral', None),\n",
       " 13: ('entailment', None),\n",
       " 14: ('entailment', None),\n",
       " 15: ('entailment', None),\n",
       " 16: ('neutral', None),\n",
       " 17: ('entailment', None),\n",
       " 18: ('neutral', None),\n",
       " 19: ('entailment', None),\n",
       " 20: ('neutral', None),\n",
       " 21: ('entailment', None),\n",
       " 22: ('neutral', None),\n",
       " 23: ('contradiction', None),\n",
       " 24: ('contradiction', None),\n",
       " 25: ('entailment', None),\n",
       " 26: ('contradiction', None),\n",
       " 27: ('neutral', None),\n",
       " 28: ('contradiction', None),\n",
       " 29: ('contradiction', None),\n",
       " 30: ('contradiction', None),\n",
       " 31: ('entailment', None),\n",
       " 32: ('contradiction', None),\n",
       " 33: ('neutral', None),\n",
       " 34: ('entailment', None),\n",
       " 35: ('entailment', None),\n",
       " 36: ('contradiction', None),\n",
       " 37: ('entailment', None),\n",
       " 38: ('entailment', None),\n",
       " 39: ('entailment', None)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse_response_batch(split=\"train\", prompt_template_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "s = \"Tell me a {adjective} joke about {content}.\"\n",
    "\n",
    "s.format(**{\"adjective\": \"funny\", \"content\": \"chickens\", \"mashall\": \"mashall\"})\n",
    "#(**{\"adjective\": \"funny\", \"content\": \"chickens\", \"mashall\": \"mashall\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = utils.Metadata()\n",
    "c2 = utils.OtherMeta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'another static'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2.static_thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teacher_response_evaluator import TeacherResponseEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = TeacherResponseEvaluator(\"anli1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.675,\n",
       " 'n_correct': 27,\n",
       " 'n_wrong': 13,\n",
       " 'n_none_responses': 40,\n",
       " 'total_reponses': 0,\n",
       " 'total_length_of_explanations': 0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate_responses_split(split = \"train\", prompt_template_id = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best prompt template for anli1 is 3, with accuracy: 0.675\n"
     ]
    }
   ],
   "source": [
    "evaluator.evaluate_train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
