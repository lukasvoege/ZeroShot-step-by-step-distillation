{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\master-thesis\\ZeroShot-step-by-step-distillation\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from teacher_query_tools import ANLITeacherQuerier, CQATeacherQuerier, ESNLITeacherQuerier, SVAMPTeacherQuerier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacher Querier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "anliTQ = ANLITeacherQuerier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yml = anliTQ.read_yaml_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'anli1',\n",
       " 'templates': {1: {'id': 1,\n",
       "   'system_message': '',\n",
       "   'user_message': '{premise} Based on that information, is the claim: {hypothesis} true, false, or inconclusive? Answer with a one sentence explanation.',\n",
       "   'label_parse': \"r'(True|False|Inconclusive)'\",\n",
       "   'explanation': True},\n",
       "  2: {'id': 2,\n",
       "   'system_message': 'You are given a context in the form of a short premise and a hypothesis about the premise. Your task is to label if the hypothesis is a \"contradiction\" (if the hypothesis contradicts the premise), an \"entailment\" (if the hypothesis entails the premise), or \"neutral\" (if the hypothesis does not contradict or entail the premise) to the premise. Also, explain very briefly (one sentence, maximum twenty words) why it is that label, but do not repeat the whole hypothesis in your explanation.',\n",
       "   'user_message': 'premise: {premise}\\\\nhypothesis: {hypothesis}',\n",
       "   'label_parse': \"r'(entailment|contradiction|neutral)'\",\n",
       "   'explanation': True},\n",
       "  3: {'id': 3,\n",
       "   'system_message': '',\n",
       "   'user_message': '{premise} Based on that information, is the claim: {hypothesis} true, false, or inconclusive? Answer without an explanation.',\n",
       "   'label_parse': \"r'(True|False|Inconclusive)'\",\n",
       "   'explanation': False}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alexandra Lendon Bastedo (9 March 1946 – 12 January 2014) was a British actress, best known for her role as secret agent Sharron Macready in the 1968 British espionage/science fiction adventure series \"The Champions\". She has been cited as a sex symbol of the 1960s and 1970s. Bastedo was a vegetarian and animal welfare advocate. Based on that information, is the claim: Bastedo didn't keep any pets because of her views on animal rights. true, false, or inconclusive? Answer with a one sentence explanation.\n",
      "RESPONSE:\n",
      "Inconclusive, as there is no information provided to confirm or deny whether Bastedo kept any pets despite her views on animal rights.\n"
     ]
    }
   ],
   "source": [
    "anliTQ._query(split=\"train\", idx=2, prompt_template_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERYING EXAMPLE 10/10...\n",
      "Batch Query completed! (Skipped 0 queries as they were already queried and stored.)\n",
      "Total Prompt Tokens: 2151\n",
      "Total Completion Tokens: 389\n",
      "Total Costs: $0.0040045\n"
     ]
    }
   ],
   "source": [
    "anliTQ._batch_query(split=\"test\", n=10, prompt_template_id=2, force_query=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "svampTQ = SVAMPTeacherQuerier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERYING EXAMPLE 12/12...\n",
      "Batch Query completed! (Skipped 0 queries as they were already queried and stored.)\n",
      "Total Prompt Tokens: 658\n",
      "Total Completion Tokens: 735\n",
      "Total Costs: $0.002457\n"
     ]
    }
   ],
   "source": [
    "svampTQ._batch_query(split=\"test\", n=12, prompt_template_id=1, force_query=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "esnli = ESNLITeacherQuerier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERYING EXAMPLE 13/13...\n",
      "Batch Query completed! (Skipped 12 queries as they were already queried and stored.)\n",
      "Total Prompt Tokens: 54\n",
      "Total Completion Tokens: 34\n",
      "Total Costs: $0.00014900000000000002\n"
     ]
    }
   ],
   "source": [
    "esnli._batch_query(split=\"train\", n=13, prompt_template_id=1, force_query=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9741/9741 [00:00<00:00, 10692.56 examples/s]\n",
      "Map: 100%|██████████| 1221/1221 [00:00<00:00, 10996.62 examples/s]\n"
     ]
    }
   ],
   "source": [
    "cqaTQ = CQATeacherQuerier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '6b819727eb8a670df26a7ffad036c119',\n",
       " 'question': '\"There are 10 apples on an apple tree.  Three fall off.  Now there are X apples.\"  What is this an example of?',\n",
       " 'choices': ['park',\n",
       "  'coloring book',\n",
       "  'garden center',\n",
       "  'math problem',\n",
       "  'gravity'],\n",
       " 'answer': 'math problem',\n",
       " 'c_0': 'park',\n",
       " 'c_1': 'coloring book',\n",
       " 'c_2': 'garden center',\n",
       " 'c_3': 'math problem',\n",
       " 'c_4': 'gravity'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cqaTQ.datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"There are 10 apples on an apple tree.  Three fall off.  Now there are X apples.\"  What is this an example of?\\n\\na)park\\nb)coloring book\\nc)garden center\\nd)math problem\\ne)gravity\n",
      "RESPONSE:\n",
      "d) math problem\n"
     ]
    }
   ],
   "source": [
    "cqaTQ._query(split=\"train\", idx=0, prompt_template_id=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\master-thesis\\ZeroShot-step-by-step-distillation\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from teacher_response_parser import ANLITeacherResponseParser\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ANLITeacherResponseParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('contradiction',\n",
       " 'The premise explicitly states that the first Ernest Jones store was opened in Oxford Street, London, not on the continent of Europe.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(\"r'(entailment|contradiction|neutral)'r'.(.*)'\", re.IGNORECASE|re.DOTALL)\n",
    "parser.parse_response(\"Contradiction. The premise explicitly states that the first Ernest Jones store was opened in Oxford Street, London, not on the continent of Europe.\", prompt_template_id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ('false',\n",
       "  'The trolleybus system currently has four urban routes, not over two.'),\n",
       " 1: ('false',\n",
       "  'Sharron Macready was a popular character in the 1960s, not the 1980s.'),\n",
       " 2: ('inconclusive',\n",
       "  'The information provided does not give any indication of whether or not Bastedo kept pets due to her views on animal rights.'),\n",
       " 3: ('inconclusive',\n",
       "  'The given information does not provide any details about how Alexandra Bastedo was named, so it is impossible to determine if she was named by her mother or not.'),\n",
       " 4: ('inconclusive',\n",
       "  'While Bastedo was known for being an animal welfare advocate and a vegetarian, it is not possible to determine whether she cared for all the animals that inhabit the earth based on the given information.'),\n",
       " 5: ('true',\n",
       "  'Bastedo was a vegetarian, indicating that she did not consume meat in her life.'),\n",
       " 6: ('false',\n",
       "  'Jesse James was a guerrilla in the pro-Confederate army during the American Civil War.'),\n",
       " 7: ('true',\n",
       "  'Rhodochiton atrosanguineus is a species within the family Plantaginaceae.'),\n",
       " 8: ('true',\n",
       "  \"Paul Beard was known as the leader of Sir Thomas Beecham's original London Philharmonic Orchestra.\"),\n",
       " 9: ('inconclusive',\n",
       "  'as there is no information provided about Paul Beard being a songwriter or composer, so it cannot be determined if he wrote any songs in 1989 or at any other time.'),\n",
       " 10: ('false',\n",
       "  \"as there is no information provided to suggest that Paul Beard wrote his first song while he was a part of Sir Adrian Boult's BBC Symphony Orchestra.\"),\n",
       " 11: ('true',\n",
       "  'Rhodochiton atrosanguineus is native to both southern Mexico and neighbouring Guatemala.'),\n",
       " 12: ('inconclusive',\n",
       "  \"The information provided does not mention Paul Beard's salary or compare it to that of other members of the orchestra.\"),\n",
       " 13: ('true',\n",
       "  'The purple bell vine, also known as Rhodochiton atrosanguineus, is native to southern Mexico and neighbouring Guatemala, indicating that it can be found in more than one country.'),\n",
       " 14: ('true',\n",
       "  'Paul Beard was a teacher for a significant portion of his life, holding posts at the Royal Academy of Music and the Guildhall School of Music.'),\n",
       " 15: ('true',\n",
       "  'as the 11th (Craigavon) Battalion, Ulster Defence Regiment was indeed a military unit formed in 1972 and later amalgamated with 2 UDR in 1991.'),\n",
       " 16: ('inconclusive',\n",
       "  'The claim does not provide enough information to determine whether Noel Black directed many American teen sex comedy films.'),\n",
       " 17: ('false',\n",
       "  'The Craigavon Battalion, Ulster Defence Regiment was formed from companies of the 2nd Battalion Ulster Defence Regiment and the 3rd Battalion Ulster Defence Regiment in 1972, not two separate units.'),\n",
       " 18: ('inconclusive',\n",
       "  'The claim does not provide enough information about the plot of the movie to determine whether the main protagonist ends up having intercourse by the end.'),\n",
       " 19: ('true',\n",
       "  'The Craigavon battalion was amalgamated with 2 UDR to form the 2nd/11th Battalion Ulster Defence Regiment.'),\n",
       " 20: ('inconclusive',\n",
       "  'The information provided does not specify the nationality or leadership of the Craigavon battalion, therefore the claim cannot be determined.'),\n",
       " 21: ('true', 'Phoebe Cates played the female lead in \"Private School.\"'),\n",
       " 22: ('inconclusive',\n",
       "  'The given information does not provide enough details to determine whether the teenage couple in \"Private School\" breaks up or not.'),\n",
       " 23: ('false',\n",
       "  \"Henry Nevill's father was the 5th Baron of Bergavenny, not the 6th.\"),\n",
       " 24: ('false',\n",
       "  'The information provided does not indicate any Scottish descent for Henry Nevill, suggesting that the claim is false.'),\n",
       " 25: ('false',\n",
       "  \"Henry Nevill's father, Sir George Nevill, 5th Baron Bergavenny, died before Henry succeeded to the barony.\"),\n",
       " 26: ('false',\n",
       "  'Henry Nevill was born between 1527 and 1535, which is in the 16th century.'),\n",
       " 27: ('inconclusive',\n",
       "  'The information provided does not specify whether Will Vodery wrote a song in 1900.'),\n",
       " 28: ('inconclusive',\n",
       "  \"The information provided does not specify the exact duration of Will Vodery's employment with Florenz Ziegfeld, therefore it is unknown if it was for a decade or not.\"),\n",
       " 29: ('false',\n",
       "  'Will Vodery was a composer, conductor, orchestrator, and arranger on Broadway, but he did not conduct most Broadway shows.')}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse_response_batch(split=\"train\", prompt_template_id=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
