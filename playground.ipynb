{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from teacher_query_tools import ANLITeacherQuerier, CQATeacherQuerier, ESNLITeacherQuerier, SVAMPTeacherQuerier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacher Querier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "anliTQ = ANLITeacherQuerier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alexandra Lendon Bastedo (9 March 1946 â€“ 12 January 2014) was a British actress, best known for her role as secret agent Sharron Macready in the 1968 British espionage/science fiction adventure series \"The Champions\". She has been cited as a sex symbol of the 1960s and 1970s. Bastedo was a vegetarian and animal welfare advocate. Based on that information, is the claim: Bastedo didn't keep any pets because of her views on animal rights. true, false, or inconclusive? Answer with a one sentence explanation.\n",
      "RESPONSE:\n",
      "Inconclusive - There is no information provided to determine whether Bastedo kept pets or not based on her views on animal rights.\n"
     ]
    }
   ],
   "source": [
    "anliTQ._query(split=\"train\", idx=2, prompt_template_id=1, dont_save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Query completed! (Skipped 41 queries as they were already queried and stored.)\n",
      "Total Prompt Tokens: 711\n",
      "Total Completion Tokens: 8\n",
      "Total Costs: $0.0010825000000000001\n"
     ]
    }
   ],
   "source": [
    "anliTQ._batch_query(split=\"train\", idxs=list(range(47)), prompt_template_id=3, force_query=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "svampTQ = SVAMPTeacherQuerier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Query completed! (Skipped 30 queries as they were already queried and stored.)\n",
      "Total Prompt Tokens: 566\n",
      "Total Completion Tokens: 635\n",
      "Total Costs: $0.002119\n"
     ]
    }
   ],
   "source": [
    "svampTQ._batch_query(split=\"train\", idxs=list(range(41)), prompt_template_id=1, force_query=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "esnli = ESNLITeacherQuerier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Query completed! (Skipped 2 queries as they were already queried and stored.)\n",
      "Total Prompt Tokens: 0\n",
      "Total Completion Tokens: 0\n",
      "Total Costs: $0\n"
     ]
    }
   ],
   "source": [
    "esnli._batch_query(split=\"train\", idxs=[0, 34191], prompt_template_id=1, force_query=False, dont_save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqaTQ = CQATeacherQuerier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Query completed! (Skipped 3 queries as they were already queried and stored.)\n",
      "Total Prompt Tokens: 148\n",
      "Total Completion Tokens: 58\n",
      "Total Costs: $0.000338\n"
     ]
    }
   ],
   "source": [
    "cqaTQ._batch_query(split=\"train\", idxs=[0, 1, 2, 100, 200], prompt_template_id=2, force_query=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teacher_response_parser import SVAMPTeacherResponseParser, ESNLITeacherResponseParser, CQATeacherResponseParser, ANLITeacherResponseParser\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = SVAMPTeacherResponseParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neutral', None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(\"(\\d+)\", re.IGNORECASE|re.DOTALL)\n",
    "parser.parse_response(\"In each row, there are 30 crayons, so in 7 rows there are 7 * 30 = <<7*30=210>>210 crayons. Answer: \\\\boxed{210}.\", pattern=pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\"(.+\\\\b)(\\d+)\")\n",
    "match = pattern.search(\"In each row, there are 30 crayons, so in 7 rows there are 7 * 30 <<7*30=210>>210 crayons. Answer: \\\\boxed{210}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('In each row, there are 30 crayons, so in 7 rows there are 7 * 30 <<7*30=210>>210 crayons. Answer: \\\\boxed{',\n",
       " '210')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ('42', None),\n",
       " 1: ('210', None),\n",
       " 2: ('34', 'Julia played with a total of'),\n",
       " 3: ('6', None),\n",
       " 4: ('7', None),\n",
       " 5: ('1088', 'The mailman should give a total of'),\n",
       " 6: ('0.5', 'Each person ate 0.5 crackers and'),\n",
       " 7: ('280', None),\n",
       " 8: ('5', None),\n",
       " 9: ('13', None),\n",
       " 10: ('12', None),\n",
       " 11: ('150', None),\n",
       " 12: ('60', None),\n",
       " 13: ('69', None),\n",
       " 14: ('9', None),\n",
       " 15: ('204', 'The farmer picked a total of'),\n",
       " 16: ('180', 'The machine made a total of'),\n",
       " 17: ('18', None),\n",
       " 18: ('18', 'The number of birds sitting on the fence is'),\n",
       " 19: ('8', None),\n",
       " 20: ('2', None),\n",
       " 21: ('60', 'The depth of the water was'),\n",
       " 22: ('66', 'The grasshopper and the frog jumped a total of'),\n",
       " 23: ('89', None),\n",
       " 24: ('130', None),\n",
       " 25: ('2', None),\n",
       " 26: ('32', None),\n",
       " 27: ('154', None),\n",
       " 28: ('345', None),\n",
       " 29: ('1', None),\n",
       " 696: ('2', None),\n",
       " 667: ('4', None),\n",
       " 63: ('12', None),\n",
       " 533: ('26', None),\n",
       " 66: ('3', None),\n",
       " 621: ('51', None),\n",
       " 346: ('7', None),\n",
       " 490: ('238', None),\n",
       " 760: ('4', None),\n",
       " 456: ('1', None)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse_response_batch(split=\"train\", prompt_template_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "s = \"Tell me a {adjective} joke about {content}.\"\n",
    "\n",
    "s.format(**{\"adjective\": \"funny\", \"content\": \"chickens\", \"mashall\": \"mashall\"})\n",
    "#(**{\"adjective\": \"funny\", \"content\": \"chickens\", \"mashall\": \"mashall\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = utils.Metadata()\n",
    "c2 = utils.OtherMeta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'another static'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2.static_thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\MasterThesis\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from teacher_response_evaluator import TeacherResponseEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = TeacherResponseEvaluator(\"anli1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not parse 'Label: Neutraxdl\n",
      "\n",
      "Explanation: The hypothesis does not contradict or entail the premise, as it introduces a new aspect (conversation) that is not mentioned in the premise.' with pattern 're.compile('(entailment|contradiction|neutral).(.*)', re.IGNORECASE|re.DOTALL)'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6428571428571429,\n",
       " 'n_correct': 27,\n",
       " 'n_wrong': 15,\n",
       " 'n_parse_errors': 1,\n",
       " 'n_none_responses': 1,\n",
       " 'total_reponses': 41,\n",
       " 'total_length_of_explanations': 6346}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate_responses_split(split = \"train\", prompt_template_id = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not parse 'The claim that the Cougars represented Washington State College is mixed, as the 1919 Washington State Cougars football team was the team that represented Washington State College during that season.' with pattern 're.compile('(True|False|Inconclusive).(.*)', re.IGNORECASE|re.DOTALL)'\n",
      "Best prompt template for anli1 is 3, with accuracy: 0.6585365853658537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teacher_writer import TeacherWriter\n",
    "tw = TeacherWriter(\"svamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix = {\"label\": {1: range(10)}, \"explanation\": {2: range(10)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw.write_teacher_responses(split=\"train\", prompt_template_id_mix=mix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
